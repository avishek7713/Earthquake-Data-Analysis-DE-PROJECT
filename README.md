# **ğŸŒ Earthquake Data Analysis Project using MICROSOFT FABRIC ğŸ“Š**

This project focuses on **Earthquake Data Analysis**, leveraging **Data Factory (ADF)** and **Databricks** for seamless data ingestion, transformation, and reporting.

## ğŸ“¥ **Data Ingestion**  

- ğŸš¨ The earthquake data is fetched from the **USGS API**: [USGS Earthquake API](https://earthquake.usgs.gov/fdsnws/event/1/#parameters).  

- ğŸ’» The JSON data is ingested into **Data Factory** via a **notebook** using Pythonâ€™s `requests` library.  

- ğŸŒ The dataset contains an object called **"features"**, where each **feature** represents an individual earthquake event.  

- ğŸ“ The extracted data is loaded into a **DataFrame**, with columns derived from `features` (geometry, id, properties, and type).  

- ğŸ’¾ This **Bronze Layer** data is stored as a table in **Lakehouse**.

## ğŸ”„ **Data Transformation (Silver Layer)**  

- ğŸ”§ A separate **notebook** processes the **Bronze Layer** data.  

- ğŸ§‘â€ğŸ”¬ The `geometry` and `properties` columns are split to extract **important metrics** for analysis.  

- â±ï¸ The **timestamp**, originally in milliseconds, is converted to **seconds** and further into **TimestampType**.  

- ğŸ’¡ The transformed data is saved as a table to serve the **Gold Layer**.

## ğŸ… **Data Enrichment & Aggregation (Gold Layer)**  

- ğŸ•°ï¸ The **Gold Layer** notebook applies a filter to extract only data **after the pipeline-defined start time**.  

- ğŸŒ A new **"country"** column is derived using **latitude & longitude** via the `reverse_geocoder` library.  

- âš™ï¸ Since `reverse_geocoder` is not available by default in **Microsoft Fabric**, a custom environment is created, and the library is installed.  

- ğŸŒ The `search()` method of `reverse_geocoder` extracts **geographical properties**, specifically the **country code (cc)**.  

- âœ‚ï¸ Additional transformations:  

  - ğŸ”´ Classification of earthquakes based on **significance**.  

  - ğŸŒ Splitting the **place_description** column to separate **country** and **place description**.  

- ğŸ† The final aggregated dataset is stored as a **reporting table**.

## ğŸ§‘â€ğŸ’» **Orchestration of Notebooks**  

- ğŸ”„ The entire pipeline of notebooks is orchestrated to automate the process, with **start_date** and **end_date** added as base parameters.  

- â³ These base parameters ensure that earthquake events are extracted for a **specified time period**, making the process **flexible** and **efficient**.

## ğŸ“Š **Power BI Reporting**  

- ğŸ“ˆ A **Power BI report** is generated using the **final dataset**, allowing:  

  - ğŸŒ **Country-wise classification** of earthquake events based on significance.  

  - ğŸ—“ï¸ **Filtering within a date range** for better insights.  

---

### ğŸš€ **Technologies Used**  

- **Data Factory (DF)** ğŸ­  

- **Notebooks for ETL Processing** ğŸ“  

- **Python (requests, pandas, reverse_geocoder)** ğŸ  

- **Microsoft Fabric (Lakehouse & Custom Environments)** ğŸ™ï¸  

- **Power BI (Visualization & Reporting)** ğŸ“Š

ğŸ“Œ *This project enables efficient earthquake data processing, transformation, and visualization for meaningful insights!* ğŸŒğŸ“Š  

---
